# üõ†Ô∏è Scripts Utilitaires

Scripts pour g√©rer les donn√©es et le d√©ploiement du syst√®me.

## üìù add_article.py

Ajoute un nouvel article au CSV des m√©tadonn√©es.

### Usage

**Mode interactif** :
```bash
python add_article.py --interactive
```

**Mode ligne de commande** :
```bash
python add_article.py --category 281 --words 250 --publisher 0
```

### Options

| Option | Description | Requis | D√©faut |
|--------|-------------|--------|--------|
| `--csv` | Chemin vers le CSV | Non | `data/articles_metadata.csv` |
| `--category` | ID de la cat√©gorie | Oui (ou -i) | - |
| `--words` | Nombre de mots | Oui (ou -i) | - |
| `--publisher` | ID de l'√©diteur | Non | 0 |
| `--timestamp` | Timestamp en ms | Non | Maintenant |
| `--interactive`, `-i` | Mode interactif | Non | False |

### Exemple Complet

```bash
# Mode interactif recommand√©
python add_article.py --interactive

# Mode ligne de commande
python add_article.py \\
  --csv data/articles_metadata.csv \\
  --category 281 \\
  --words 250 \\
  --publisher 0
```

### ‚ö†Ô∏è Important

Apr√®s l'ajout d'articles :
1. Uploader le CSV mis √† jour vers Azure Storage
2. G√©n√©rer les embeddings pour le nouvel article (optionnel mais recommand√©)
3. R√©entra√Æner le mod√®le ALS si des interactions sont ajout√©es

---

## üì§ upload_data_to_azure.py

Upload les donn√©es vers Azure Blob Storage.

### Usage

**Uploader toutes les donn√©es** :
```bash
python upload_data_to_azure.py --all
```

**Uploader des fichiers sp√©cifiques** :
```bash
# Mod√®le ALS uniquement
python upload_data_to_azure.py --model

# M√©tadonn√©es uniquement
python upload_data_to_azure.py --metadata

# Embeddings uniquement
python upload_data_to_azure.py --embeddings
```

**Lister les fichiers existants** :
```bash
python upload_data_to_azure.py --list
```

### Options

| Option | Description |
|--------|-------------|
| `--all` | Uploader toutes les donn√©es |
| `--model` | Uploader le mod√®le ALS |
| `--metadata` | Uploader les m√©tadonn√©es articles |
| `--embeddings` | Uploader les embeddings r√©duits |
| `--list` | Lister les fichiers existants |
| `--model-path` | Chemin custom du mod√®le (d√©faut: `models/als_model.pkl`) |
| `--metadata-path` | Chemin custom des m√©tadonn√©es (d√©faut: `data/articles_metadata.csv`) |
| `--embeddings-path` | Chemin custom des embeddings (d√©faut: `data/articles_embeddings_reduced.pickle`) |
| `--no-overwrite` | Ne pas √©craser les fichiers existants |

### Configuration

Le script utilise la variable d'environnement `AZURE_STORAGE_CONNECTION_STRING`.

**Option 1 - Variable d'environnement** :
```bash
export AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;..."
```

**Option 2 - Fichier .env** :
```bash
# Cr√©er un fichier .env
echo 'AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;..."' > .env
```

### Exemple Complet

```bash
# 1. Configurer la connection string
export AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=mystorageaccount;AccountKey=...;EndpointSuffix=core.windows.net"

# 2. Lister les fichiers existants
python upload_data_to_azure.py --list

# 3. Uploader toutes les donn√©es
python upload_data_to_azure.py --all

# 4. V√©rifier que les fichiers sont bien upload√©s
python upload_data_to_azure.py --list
```

### Fichiers Upload√©s

| Fichier Local | Container Azure | Blob Name | Taille |
|---------------|-----------------|-----------|--------|
| `models/als_model.pkl` | `models` | `als_model.pkl` | ~130 KB |
| `data/articles_metadata.csv` | `data` | `articles_metadata.csv` | ~11 MB |
| `data/articles_embeddings_reduced.pickle` | `data` | `articles_embeddings_reduced.pickle` | ~111 MB |

---

## üîÑ train_model.py (√Ä venir)

Script de r√©entra√Ænement du mod√®le ALS.

**Fonctionnalit√©s pr√©vues** :
- Charger les nouveaux clics depuis Azure Storage
- Fusionner avec les clics historiques
- Entra√Æner un nouveau mod√®le ALS
- Comparer les performances (ancien vs nouveau)
- Upload du nouveau mod√®le vers Azure Storage
- D√©ploiement automatique

**Usage pr√©vu** :
```bash
python train_model.py \\
  --clicks-path data/clicks/ \\
  --new-clicks-container clicks \\
  --output models/als_model_new.pkl \\
  --evaluate
```

---

## üîß D√©pendances

Les scripts n√©cessitent les d√©pendances suivantes :

```bash
pip install azure-storage-blob python-dotenv pandas
```

Ou utiliser le fichier requirements du backend :

```bash
pip install -r ../backend/azure_function/requirements.txt
```

---

## üìã Workflow Recommand√©

### Ajout d'un nouvel article

1. **Ajouter au CSV** :
   ```bash
   python add_article.py --interactive
   ```

2. **Uploader vers Azure** :
   ```bash
   python upload_data_to_azure.py --metadata
   ```

3. **Red√©marrer la Function App** (pour recharger les m√©tadonn√©es) :
   ```bash
   az functionapp restart \\
     --name your-function-app \\
     --resource-group your-resource-group
   ```

### Mise √† jour du mod√®le

1. **R√©entra√Æner** :
   ```bash
   python train_model.py --evaluate
   ```

2. **Uploader le nouveau mod√®le** :
   ```bash
   python upload_data_to_azure.py --model
   ```

3. **Red√©marrer la Function App** :
   ```bash
   az functionapp restart \\
     --name your-function-app \\
     --resource-group your-resource-group
   ```

---

## üÜò Troubleshooting

### Erreur: "STORAGE_CONNECTION_STRING non trouv√©e"

**Solution** :
```bash
export AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net"
```

### Erreur: "Container 'xxx' n'existe pas"

**Solution** : Les containers sont cr√©√©s automatiquement lors de l'upload. Si l'erreur persiste :
```bash
az storage container create --name data --connection-string "$AZURE_STORAGE_CONNECTION_STRING"
az storage container create --name models --connection-string "$AZURE_STORAGE_CONNECTION_STRING"
az storage container create --name clicks --connection-string "$AZURE_STORAGE_CONNECTION_STRING"
```

### Erreur: "Fichier non trouv√©"

**Solution** : V√©rifiez que vous √™tes dans le bon r√©pertoire et que les chemins sont corrects :
```bash
ls -la models/als_model.pkl
ls -la data/articles_metadata.csv
ls -la data/articles_embeddings_reduced.pickle
```

---

**Derni√®re mise √† jour** : Octobre 2025
