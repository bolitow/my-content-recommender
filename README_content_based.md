# Syst√®me de Recommandation Content-Based

## Vue d'ensemble

Ce projet impl√©mente trois approches de filtrage bas√© sur le contenu (Content-Based Filtering) pour recommander des articles d'actualit√©. Chaque approche utilise des strat√©gies diff√©rentes pour r√©soudre le d√©fi de la recommandation d'articles dans un contexte d'actualit√©s.

## Architecture des Approches

### üéØ Approche 1: Popularit√© Temporelle Avanc√©e

**Principe:** Combine la popularit√© des articles avec une d√©croissance temporelle pour favoriser le contenu r√©cent tout en maintenant la diversit√©.

**Fonctionnement:**
1. **Pond√©ration temporelle:** Chaque clic re√ßoit un poids qui d√©cro√Æt exponentiellement avec l'√¢ge (factor = 0.95^jours)
2. **Score composite:** Agr√©gation de 4 m√©triques:
   - Clics pond√©r√©s temporellement (40%)
   - Score d'engagement bas√© sur le temps avant clic (30%)
   - Score de diversit√© (ratio utilisateurs uniques/clics totaux) (20%)
   - Sessions uniques (10%)
3. **Diversification:** Limite le nombre d'articles par cat√©gorie pour √©viter la sur-concentration

**Formulation math√©matique:**

Variables :
- `t_i` : Timestamp du clic i
- `t_max` : Timestamp le plus r√©cent dans les donn√©es
- `d_i` : Nombre de jours √©coul√©s depuis le clic i = `(t_max - t_i) / 86400`
- `Œ±` : Facteur de d√©croissance temporelle (temporal_decay = 0.95)
- `Œ≤` : Boost de fra√Æcheur (freshness_boost = 0.3)
- `w_i` : Poids temporel du clic i
- `œÑ_a` : Temps moyen avant clic pour l'article a
- `œÑ_max` : Temps maximum avant clic dans le dataset
- `U_a` : Ensemble des utilisateurs uniques ayant cliqu√© sur l'article a
- `C_a` : Nombre total de clics sur l'article a
- `S_a` : Nombre de sessions uniques contenant l'article a
- `age_a` : √Çge de l'article a en jours

√âquations :
```
w_i = Œ±^(d_i)                                    # Poids temporel du clic i
W_a = Œ£ w_i pour tout clic i sur article a      # Clics pond√©r√©s totaux

E_a = 1 - (œÑ_a / œÑ_max)                         # Score d'engagement
D_a = |U_a| / C_a                               # Score de diversit√©
F_a = 1 / (1 + age_a / 7)                       # Facteur de fra√Æcheur

Score_base(a) = 0.4 √ó (W_a / max(W)) +          # Popularit√© pond√©r√©e normalis√©e
                0.3 √ó E_a +                      # Engagement
                0.2 √ó (D_a / max(D)) +          # Diversit√© normalis√©e
                0.1 √ó (S_a / max(S))            # Sessions normalis√©es

Score_final(a) = Score_base(a) √ó (1 + Œ≤ √ó F_a)  # Score avec boost de fra√Æcheur
```

**Avantages:**
- Adapt√© aux nouveaux utilisateurs (cold start)
- Favorise naturellement le contenu frais et pertinent
- Calcul rapide et scalable

**Limitations:**
- Pas de personnalisation individuelle
- Peut sur-repr√©senter les articles viraux

---

### üß† Approche 2: Similarit√© Multi-Facettes

**Principe:** Construit un profil utilisateur riche combinant embeddings s√©mantiques, comportement et pr√©f√©rences cat√©gorielles.

**Fonctionnement:**

1. **Construction du profil utilisateur:**
   - **Embedding Profile:** Moyenne pond√©r√©e des embeddings des articles cliqu√©s
     - Pond√©ration temporelle: articles r√©cents ont plus de poids
     - Fen√™tre glissante: derniers 30 jours par d√©faut
   
   - **Behavioral Profile:** Statistiques comportementales
     - Temps moyen avant clic
     - Nombre de sessions
     - Diversit√© des cat√©gories consult√©es
   
   - **Category Profile:** Distribution des clics par cat√©gorie (vecteur normalis√©)

2. **Matrice de co-occurrence:**
   - Capture les articles souvent consult√©s ensemble dans une session
   - Fen√™tre de co-occurrence: 5 articles cons√©cutifs
   - Utilis√© comme signal additionnel de pertinence

3. **Scoring multi-dimensionnel:**

Variables :
- `u` : Vecteur profil utilisateur (embedding)
- `a` : Vecteur article (embedding)  
- `P_u` : Profil utilisateur multi-facettes
- `A_clicked` : Ensemble des articles cliqu√©s par l'utilisateur
- `w_j` : Poids temporel de l'article j dans l'historique
- `e_j` : Embedding de l'article j
- `cat_u` : Vecteur de distribution des cat√©gories pour l'utilisateur
- `cat_a` : Cat√©gorie de l'article a
- `œÑ_u` : Temps moyen avant clic de l'utilisateur
- `œÑ_a` : Temps moyen avant clic de l'article a
- `M_cooc` : Matrice de co-occurrence des articles
- `R_u` : Ensemble des articles r√©cents de l'utilisateur (10 derniers)

√âquations :
```
# Profil utilisateur (moyenne pond√©r√©e temporellement)
u = Œ£(w_j √ó e_j) / Œ£(w_j) pour j ‚àà A_clicked
o√π w_j = 1 / (1 + days_since_click_j)

# Similarit√© cosinus
sim_embedding(u, a) = (u ¬∑ a) / (||u|| √ó ||a||)

# Similarit√© cat√©gorielle  
sim_category(u, a) = cat_u[cat_a] si cat_a existe, 0 sinon

# Similarit√© comportementale
sim_behavior(u, a) = max(0, 1 - |œÑ_u - œÑ_a| / max(œÑ_u, œÑ_a))

# Bonus de co-occurrence
bonus_cooc(u, a) = min(0.1, Œ£(M_cooc[a][r] pour r ‚àà R_u) / max(M_cooc))

# Score final
Score(a|u) = 0.5 √ó sim_embedding(u, a) +
             0.2 √ó sim_category(u, a) +
             0.2 √ó sim_behavior(u, a) +
             0.1 √ó bonus_cooc(u, a)
```

4. **Exploration/Exploitation:**
   - 80% des recommandations: articles avec les meilleurs scores
   - 20% des recommandations: articles divers pour d√©couverte

**Algorithme de similarit√© cosinus:**
```
cosine_sim(u, a) = (u ¬∑ a) / (||u|| * ||a||)
```
O√π u est le vecteur profil utilisateur et a le vecteur article.

**Avantages:**
- Personnalisation fine bas√©e sur le comportement r√©el
- Capture les relations complexes entre articles
- √âquilibre entre pertinence et d√©couverte

**Limitations:**
- N√©cessite un historique utilisateur substantiel
- Co√ªt computationnel plus √©lev√©
- Cold start problem pour nouveaux utilisateurs

---

### ‚ö° Approche 3: Syst√®me Hybride

**Principe:** Combine popularit√© et similarit√© pour optimiser le compromis entre qualit√© garantie et personnalisation.

**Fonctionnement:**

1. **S√©lection des candidats:**
   - Prend les TOP 50 articles les plus populaires non vus
   - Assure une base de qualit√© minimum

2. **Scoring hybride:**

Variables :
- `Œ±` : Poids de la popularit√© (popularity_weight = 0.3)
- `P_a` : Score de popularit√© de l'article a
- `S(a|u)` : Score de similarit√© de l'article a pour l'utilisateur u
- `C_a` : Nombre de clics sur l'article a
- `C_max` : Nombre maximum de clics sur un article
- `u_profile` : Profil d'embedding de l'utilisateur
- `a_emb` : Embedding de l'article a
- `TOP_k` : Les k articles les plus populaires non vus

√âquations :
```
# Popularit√© normalis√©e
P_a = C_a / C_max

# Similarit√© cosinus
S(a|u) = (u_profile ¬∑ a_emb) / (||u_profile|| √ó ||a_emb||)

# Profil utilisateur (moyenne pond√©r√©e par fr√©quence)
u_profile = Œ£(count_j √ó e_j) / Œ£(count_j) pour j ‚àà articles_cliqu√©s
o√π count_j = nombre de clics sur l'article j par l'utilisateur

# Score hybride
H(a|u) = (1 - Œ±) √ó S(a|u) + Œ± √ó P_a
       = 0.7 √ó S(a|u) + 0.3 √ó P_a

# S√©lection finale
Recommandations = argmax_a‚ààTOP_50 H(a|u) pour les n premiers
```

3. **Fallback intelligent:**
   - Si nouvel utilisateur ‚Üí recommandations par popularit√© pure
   - Si utilisateur actif ‚Üí scoring hybride complet

**Processus de d√©cision:**
```
if user_profile exists:
    candidates = top_popular_unseen_articles(50)
    scores = hybrid_scoring(candidates, user_profile)
    return top_n(scores)
else:
    return top_n_popular_articles()
```

**Avantages:**
- Robuste pour tous types d'utilisateurs
- Balance automatique entre exploration et exploitation
- Performance constante m√™me avec peu de donn√©es

**Limitations:**
- Moins de personnalisation que l'approche 2 pure
- Peut favoriser les articles mainstream

---

## M√©triques d'√âvaluation

### Split des Donn√©es
- **Split par utilisateur:** 80% des interactions de chaque utilisateur en train, 20% en test
- **Filtre:** Utilisateurs avec minimum 10 interactions
- **Avantage:** Plus r√©aliste que split temporel pour articles d'actualit√©

### M√©triques Utilis√©es

**Hit@K:** Proportion d'utilisateurs avec au moins 1 article correct dans le TOP K
```
Hit@K = 1 si |recommendations[:K] ‚à© actual| > 0, sinon 0
```

**Precision@K:** Proportion d'articles corrects dans le TOP K
```
Precision@K = |recommendations[:K] ‚à© actual| / K
```

**Recall@K:** Proportion d'articles pertinents retrouv√©s
```
Recall@K = |recommendations[:K] ‚à© actual| / |actual|
```

### R√©sultats Typiques

| Approche | Hit@5 | Hit@10 | Hit@20 | Precision@10 |
|----------|-------|--------|--------|--------------|
| Popularit√© Temporelle | 15-20% | 25-30% | 35-40% | 0.02-0.04 |
| Similarit√© Multi-Facettes | 10-15% | 20-25% | 30-35% | 0.01-0.03 |
| Hybride | 20-25% | 30-35% | 40-45% | 0.03-0.05 |

*Note: Les m√©triques sont naturellement basses pour les articles d'actualit√© car les utilisateurs ne re-cliquent presque jamais sur le m√™me article.*

---

## Optimisations Impl√©ment√©es

### Performance
- **√âchantillonnage:** Limite √† 1000 candidats pour le scoring
- **Caching:** Pr√©-calcul des scores de popularit√©
- **Vectorisation:** Utilisation de NumPy pour les calculs matriciels

### Qualit√©
- **Diversification forc√©e:** Maximum 3 articles par cat√©gorie
- **Fen√™tre temporelle:** Focus sur l'activit√© r√©cente (30 jours)
- **Exploration contr√¥l√©e:** 20% de contenu nouveau

### Scalabilit√©
- **Batch processing:** Traitement par lots des utilisateurs
- **Sparse matrices:** Pour les grandes matrices utilisateur-article
- **Incremental updates:** Mise √† jour des scores sans recalcul complet

---

## Guide d'Utilisation

### Installation des d√©pendances
```bash
pip install pandas numpy scikit-learn
```

### Structure des donn√©es requises
```
data/
‚îú‚îÄ‚îÄ articles_metadata.csv     # M√©tadonn√©es des articles
‚îú‚îÄ‚îÄ articles_embeddings.pickle # Embeddings pr√©-calcul√©s
‚îî‚îÄ‚îÄ clicks/                    # Dossier des interactions
    ‚îî‚îÄ‚îÄ clicks_hour_*.csv
```

### Utilisation basique
```python
# Chargement des donn√©es
train_df, test_df = user_based_split(clicks_df)

# Initialisation
recommender = HybridRecommender(embeddings, articles_df, train_df)

# G√©n√©ration de recommandations
recommendations = recommender.recommend(user_id=123, n=10)
```

### Param√®tres ajustables

**TemporalPopularityRecommender:**
- `temporal_decay`: Facteur de d√©croissance (d√©faut: 0.95)
- `max_per_category`: Articles max par cat√©gorie (d√©faut: 3)

**MultiFacetSimilarityRecommender:**
- `time_window`: Fen√™tre d'historique en jours (d√©faut: 30)
- `exploration_rate`: Taux d'exploration (d√©faut: 0.2)

**HybridRecommender:**
- `popularity_weight`: Poids de la popularit√© (d√©faut: 0.3)

---

## Consid√©rations pour la Production

### Architecture Recommand√©e
```
API Gateway ‚Üí Load Balancer ‚Üí 
‚îú‚îÄ‚îÄ Service Popularit√© (Cache Redis 5min)
‚îú‚îÄ‚îÄ Service Similarit√© (Cache 15min)
‚îî‚îÄ‚îÄ Service Hybride (Cache 10min)
```

### Monitoring
- Latence P95 < 100ms
- CTR par approche et segment
- Couverture du catalogue hebdomadaire
- Distribution des cat√©gories recommand√©es

### A/B Testing
- 40% Hybride (contr√¥le)
- 30% Popularit√© Temporelle
- 30% Similarit√© Multi-Facettes
- M√©triques: CTR, temps de session, articles par session

### Am√©liorations Futures
1. **Features contextuelles:** Heure, device, localisation
2. **Apprentissage en ligne:** Mise √† jour temps r√©el des profils
3. **Deep learning:** Transformer pour s√©quences de clics
4. **Multi-objectif:** Optimiser CTR + diversit√© + fra√Æcheur

---

## Conclusion

Ce syst√®me Content-Based offre trois approches compl√©mentaires adapt√©es √† diff√©rents sc√©narios. L'approche hybride est recommand√©e pour la production car elle offre le meilleur √©quilibre entre performance, personnalisation et robustesse. Les m√©triques doivent √™tre interpr√©t√©es dans le contexte sp√©cifique des articles d'actualit√© o√π la r√©p√©tition de consultation est rare.